{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c2b4a0b",
   "metadata": {},
   "source": [
    "# Residual Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a563bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from resnets_utils import *\n",
    "\n",
    "from torch.utils.data import DataLoader, sampler, TensorDataset\n",
    "\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c0f613",
   "metadata": {},
   "source": [
    "## 2 - Building a Residual Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc6f9b1",
   "metadata": {},
   "source": [
    "### 2.1 - The identity block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "560737d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class identity_block(nn.Module):\n",
    "    \n",
    "    def __init__(self, f, filters, in_channels):\n",
    "        super(identity_block, self).__init__()\n",
    "        F1, F2, F3 = filters\n",
    "        \n",
    "        self.conv2d_1 = nn.Conv2d(in_channels, F1, kernel_size=1, padding=\"valid\")\n",
    "        self.bn_1 = nn.BatchNorm2d(F1)\n",
    "        \n",
    "        # Second component\n",
    "        self.conv2d_2 = nn.Conv2d(F1, F2, kernel_size=f, padding=\"same\")\n",
    "        self.bn_2 = nn.BatchNorm2d(F2)\n",
    "        \n",
    "        # Third component\n",
    "        self.conv2d_3 = nn.Conv2d(F2, F3, kernel_size=1, padding=\"valid\")\n",
    "        self.bn_3 = nn.BatchNorm2d(F3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_copy = x\n",
    "        \n",
    "        ## Main Path\n",
    "        x = F.relu(self.bn_1(self.conv2d_1(x)))\n",
    "        x = F.relu(self.bn_2(self.conv2d_2(x)))\n",
    "        x = self.bn_3(self.conv2d_3(x))\n",
    "        \n",
    "        ## Combine two paths\n",
    "        x = F.relu(x + x_copy)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d046a2",
   "metadata": {},
   "source": [
    "### 2.2 - Convolutional block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0221f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class convolutional_block(nn.Module):\n",
    "    \n",
    "    def __init__(self, f, filters, in_channels, s=2):\n",
    "        super(convolutional_block, self).__init__()\n",
    "        F1, F2, F3 = filters\n",
    "        \n",
    "        self.conv2d_1 = nn.Conv2d(in_channels, F1, kernel_size=1, stride=s, padding=\"valid\")\n",
    "        self.bn_1 = nn.BatchNorm2d(F1)\n",
    "        \n",
    "        # Second component\n",
    "        self.conv2d_2 = nn.Conv2d(F1, F2, kernel_size=f, padding=\"same\")\n",
    "        self.bn_2 = nn.BatchNorm2d(F2)\n",
    "        \n",
    "        # Third component\n",
    "        self.conv2d_3 = nn.Conv2d(F2, F3, kernel_size=1, padding=\"valid\")\n",
    "        self.bn_3 = nn.BatchNorm2d(F3)\n",
    "        \n",
    "        # Shortcut component\n",
    "        self.conv2d_shortcut = nn.Conv2d(in_channels, F3, kernel_size=1, stride=s, padding=\"valid\")\n",
    "        self.bn_shortcut = nn.BatchNorm2d(F3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_copy = x\n",
    "        \n",
    "        ## Main Path\n",
    "        x = F.relu(self.bn_1(self.conv2d_1(x)))\n",
    "        x = F.relu(self.bn_2(self.conv2d_2(x)))\n",
    "        x = self.bn_3(self.conv2d_3(x))\n",
    "        \n",
    "        ## Shortcut path\n",
    "        x_copy = self.bn_shortcut(self.conv2d_shortcut(x_copy))\n",
    "        \n",
    "        ## Combine two paths\n",
    "        x = F.relu(x + x_copy)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a35bd5",
   "metadata": {},
   "source": [
    "### 2.3 - ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6182463",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0394ae3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet50 = nn.Sequential(\n",
    "    nn.ZeroPad2d(3),\n",
    "    \n",
    "    # Stage 1\n",
    "    nn.Conv2d(3, 64, kernel_size=7, stride=2),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "\n",
    "    # Stage 2\n",
    "    convolutional_block(3, [64, 64, 256], in_channels=64, s=1),\n",
    "    identity_block(3, [64, 64, 256], in_channels=256),\n",
    "    identity_block(3, [64, 64, 256], in_channels=256),\n",
    "\n",
    "    # Stage 3\n",
    "    convolutional_block(3, [128, 128, 512], in_channels=256, s=2),\n",
    "    identity_block(3, [128, 128, 512], in_channels=512),\n",
    "    identity_block(3, [128, 128, 512], in_channels=512),\n",
    "    identity_block(3, [128, 128, 512], in_channels=512),\n",
    "\n",
    "    # Stage 4\n",
    "    convolutional_block(3, [256, 256, 1024], in_channels=512, s=2),\n",
    "    identity_block(3, [256, 256, 1024], in_channels=1024),\n",
    "    identity_block(3, [256, 256, 1024], in_channels=1024),\n",
    "    identity_block(3, [256, 256, 1024], in_channels=1024),\n",
    "    identity_block(3, [256, 256, 1024], in_channels=1024),\n",
    "    identity_block(3, [256, 256, 1024], in_channels=1024),\n",
    "\n",
    "    # Stage 5\n",
    "    convolutional_block(3, [512, 512, 2048], in_channels=1024, s=2),\n",
    "    identity_block(3, [512, 512, 2048], in_channels=2048),\n",
    "    identity_block(3, [512, 512, 2048], in_channels=2048),\n",
    "\n",
    "    # Average Pooling\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "    # Output Layer\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(2048, num_classes)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "39243df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214\n"
     ]
    }
   ],
   "source": [
    "params = list(ResNet50.parameters())\n",
    "print(len(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "92e1b463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training exampels: 1080\n",
      "Number of test exampels: 120\n",
      "Shape of X_train: (1080, 3, 64, 64)\n",
      "Shape of Y_train: (1080,)\n",
      "Shape of X_test: (120, 3, 64, 64)\n",
      "Shape of Y_test: (120,)\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "X_train_orig, Y_train, X_test_orig, Y_test, classes = load_dataset()\n",
    "\n",
    "# Swap axes to make (N, C, H, W)\n",
    "X_train_orig = np.transpose(X_train_orig, (0, 3, 1, 2))\n",
    "X_test_orig = np.transpose(X_test_orig, (0, 3, 1, 2))\n",
    "\n",
    "# Make (N,)\n",
    "Y_train = Y_train.ravel()\n",
    "Y_test = Y_test.ravel()\n",
    "\n",
    "# Normalize values to [0, 1]\n",
    "X_train = X_train_orig / 255\n",
    "X_test = X_test_orig / 255\n",
    "\n",
    "print(f\"Number of training exampels: {X_train.shape[0]}\")\n",
    "print(f\"Number of test exampels: {X_test.shape[0]}\")\n",
    "print(f\"Shape of X_train: {X_train.shape}\")\n",
    "print(f\"Shape of Y_train: {Y_train.shape}\")\n",
    "print(f\"Shape of X_test: {X_test.shape}\")\n",
    "print(f\"Shape of Y_test: {Y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8b65ed1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "Y_train_tensor = torch.tensor(Y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "Y_test_tensor = torch.tensor(Y_test, dtype=torch.long)\n",
    "\n",
    "train_set = TensorDataset(X_train_tensor, Y_train_tensor)\n",
    "test_set = TensorDataset(X_test_tensor, Y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=4, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8c05f7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCH = 10\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(ResNet50.parameters(), lr=1e-4, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ea1c5a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    num_correct = 0\n",
    "    num_total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            predictions = model(inputs)\n",
    "            _, y_pred = torch.max(predictions, 1)\n",
    "            num_correct += (y_pred == targets).sum().item()\n",
    "            num_total += targets.shape[0]\n",
    "    \n",
    "    return num_correct/num_total\n",
    "    \n",
    "    \n",
    "def train(model, loss_fn, optimizer, train_loader, test_loader, epochs=1, verbose=True):\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.\n",
    "        for i, (inputs, targets) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(inputs)\n",
    "            loss = loss_fn(predictions, targets)\n",
    "            running_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        running_loss /= len(train_loader)\n",
    "    \n",
    "        if verbose:\n",
    "            acc = evaluate(model, test_loader)\n",
    "            print(f\"Epoch: {epoch + 1} | Avg Loss: {loss.item()} | Test accuracy: {acc}\")\n",
    "        \n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b7de69c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Avg Loss: 0.7381016612052917 | Test accuracy: 0.5166666666666667\n",
      "Epoch: 2 | Avg Loss: 0.5188310146331787 | Test accuracy: 0.625\n",
      "Epoch: 3 | Avg Loss: 0.9953516721725464 | Test accuracy: 0.7583333333333333\n",
      "Epoch: 4 | Avg Loss: 0.19300423562526703 | Test accuracy: 0.8416666666666667\n",
      "Epoch: 5 | Avg Loss: 0.22030915319919586 | Test accuracy: 0.875\n",
      "Epoch: 6 | Avg Loss: 0.801445484161377 | Test accuracy: 0.8583333333333333\n",
      "Epoch: 7 | Avg Loss: 0.021620137616991997 | Test accuracy: 0.8833333333333333\n",
      "Epoch: 8 | Avg Loss: 0.021780110895633698 | Test accuracy: 0.8916666666666667\n",
      "Epoch: 9 | Avg Loss: 1.2491304874420166 | Test accuracy: 0.925\n",
      "Epoch: 10 | Avg Loss: 0.46594473719596863 | Test accuracy: 0.8916666666666667\n"
     ]
    }
   ],
   "source": [
    "train(ResNet50, loss_fn, optimizer, train_loader, test_loader, epochs=NUM_EPOCH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
